<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>Gaclib -- Home -- Lexical colorizer with context-sensitive tokens</title>
<link rel="shortcut icon" href="../../favicon.ico">
<link rel="stylesheet" type="text/css" href="../../global.css">
<link rel="stylesheet" type="text/css" href="../../article.css">
<link rel="stylesheet" type="text/css" href="../../navigation.css">
<link rel="stylesheet" type="text/css" href="../../category.css">
<script src="../../scripts/rootView.js"></script>
<script src="../../scripts/homeView.js"></script>
<script src="../../scripts/homeCategoryArticleView.js"></script>

</head>
<body>
<div id="MVC-ViewContainer"></div>
<script lang="javascript">
{
  const mvcModel = {
  "path": [
    "string-processing",
    "lexer-cs"
  ]
};
  const mvcViews = [
  {
    "targetObject": "MVC-ViewContainer",
    "viewName": "Gaclib-RootView"
  },
  {
    "targetObject": "rootViewContainer",
    "viewName": "Gaclib-HomeView"
  },
  {
    "targetObject": "homeViewContainer",
    "viewName": "Gaclib-HomeCategoryArticleView"
  }
];
  const activeButton = "Home";
  const activeCategory = "String";
  const homeArticle = {
  "index": false,
  "numberBeforeTitle": false,
  "topic": {
    "kind": "Topic",
    "title": "Welcome to Gaclib!",
    "content": [
      {
        "kind": "Paragraph",
        "content": [
          {
            "kind": "Text",
            "text": "\n            Gaclib is a GPU accelerated C++ User Interface library.\n            It is flexible, customizable with rich amount of built-in layout and controls.\n            It also supports control templates, list item templates, MVVM, localization, animation, etc.\n            More importantly, even if the UI is very complex, it still has good performance in interaction.\n            You can find it at "
          },
          {
            "kind": "PageLink",
            "href": "https://github.com/vczh-libraries/Release",
            "content": [
              {
                "kind": "Text",
                "text": "github"
              }
            ]
          },
          {
            "kind": "Text",
            "text": ".\n            This library provide many useful features.\n            If you don't need all features,\n            you can just use a subset of released C++ files to reduce the size of the executable.\n        "
          }
        ]
      },
      {
        "kind": "Paragraph",
        "content": [
          {
            "kind": "Image",
            "src": "/resources/home/xml_HelloWorld.png"
          }
        ]
      }
    ]
  }
};
  const categoryArticle = {
  "index": false,
  "numberBeforeTitle": false,
  "topic": {
    "kind": "Topic",
    "title": "Lexical colorizer with context-sensitive tokens",
    "content": [
      {
        "kind": "Paragraph",
        "content": [
          {
            "kind": "Text",
            "text": "\n            When regular expression is not enough to define a token,\n            you can register a callback to modify the token,\n            it is called on every recognized token.\n            For colorization, a token could be provided in multiple line buffers,\n            the callback is also given the information to handle such case.\n        "
          }
        ]
      },
      {
        "kind": "Paragraph",
        "content": [
          {
            "kind": "Text",
            "text": "\n            Context sensitive colorization is also a very powerful feature provided by "
          },
          {
            "kind": "Strong",
            "content": [
              {
                "kind": "Text",
                "text": "RegexLexer"
              }
            ]
          },
          {
            "kind": "Text",
            "text": ".\n        "
          }
        ]
      },
      {
        "kind": "Paragraph",
        "content": [
          {
            "kind": "Program",
            "code": "int main()\r\n{\r\n    List<WString> tokenDefs;\r\n    tokenDefs.Add(L\"/d+\");\r\n    tokenDefs.Add(L\"[a-zA-Z_]/w*\");\r\n    tokenDefs.Add(L\"\\\"([^\\\"/\\\\]|/\\\\/.)*\\\"\");\r\n    tokenDefs.Add(L\"R\\\"[^(]*/(\");\r\n    tokenDefs.Add(L\"[(){};]\");\r\n    tokenDefs.Add(L\"/s+\");\r\n    tokenDefs.Add(L\"///*+([^//*]|/*+[^//])*/*+//\");\r\n\r\n    const wchar_t* lines[] = {\r\n        L\"/*********************\",\r\n        L\"MAIN.CPP\",\r\n        L\"*********************/\",\r\n        L\"\",\r\n        L\"int main()\",\r\n        L\"{\",\r\n        L\"    printf(\\\"This is a \\\\\\\"simple\\\\\\\" text.\\\");\",\r\n        L\"    printf(R\\\"____(This is a\",\r\n        L\"\\\"multiple lined\\\"\",\r\n        L\"literal text)____\\\");\",\r\n        L\"    return 0;\",\r\n        L\"}\",\r\n    };\r\n\r\n    struct Argument\r\n    {\r\n        // for a real colorizer, you can put a color buffer here.\r\n        // the buffer is reused for every line of code.\r\n        // but for the demo, I put the current processing text instead.\r\n        // so that I am able to print what is processed.\r\n        const wchar_t* processingText = nullptr;\r\n    } argument;\r\n\r\n    struct InterTokenState\r\n    {\r\n        WString postfix;\r\n    };\r\n\r\n    RegexProc proc;\r\n    proc.argument = &argument;\r\n    proc.colorizeProc = [](void* argument, vint start, vint length, vint token)\r\n    {\r\n        // this is guaranteed by \"proc.argument = &argument;\"\r\n        auto text = reinterpret_cast<Argument*>(argument)->processingText;\r\n        Console::WriteLine(itow(token) + L\": <\" + WString(text + start, length) + L\">\");\r\n    };\r\n    proc.deleter = [](void* interTokenState)\r\n    {\r\n        delete reinterpret_cast<InterTokenState*>(interTokenState);\r\n    };\r\n    proc.extendProc = [](void* argument, const wchar_t* reading, vint length, bool completeText, RegexProcessingToken& processingToken)\r\n    {\r\n        // 3 is R\"[^(]*/(\r\n        // 7 is not used in tokenDefs, it is occupied to represent an extended literal string\r\n        if (processingToken.token == 3 || processingToken.token == 7)\r\n        {\r\n            // for calling wcsstr, create a buffer that is zero terminated\r\n            WString readingBuffer = length == -1 ? WString(reading, false) : WString(reading, length);\r\n            reading = readingBuffer.Buffer();\r\n\r\n            // get the postfix, which is )____\" in this case\r\n            WString postfix;\r\n            if (processingToken.interTokenState)\r\n            {\r\n                postfix = reinterpret_cast<InterTokenState*>(processingToken.interTokenState)->postfix;\r\n            }\r\n            else\r\n            {\r\n                postfix = L\")\" + WString(reading + 2, processingToken.length - 3) + L\"\\\"\";\r\n            }\r\n\r\n            // try to find if the postfix, which is )____\" in this case, appear in the given buffer\r\n            auto find = wcsstr(reading, postfix.Buffer());\r\n            if (find)\r\n            {\r\n                // if we find the postfix, it means we find the end of the literal string\r\n                // here processingToken.token automatically becomes 7\r\n                // interTokenState needs to be nullptr to indicate this\r\n                processingToken.length = (vint)(find - reading) + postfix.Length();\r\n                processingToken.completeToken = true;\r\n                processingToken.interTokenState = nullptr;\r\n            }\r\n            else\r\n            {\r\n                // if we don't find the postfix, it means the end of the literal string is in future lines\r\n                // we need to set the token to 7, which is the real token id for literal strings\r\n                // since we change any token from 3 to 7, 3 will never be passed to colorizeProc in \"token\" argument\r\n                processingToken.length = readingBuffer.Length();\r\n                processingToken.token = 7;\r\n                processingToken.completeToken = false;\r\n\r\n                // we need to ensure that interTokenState is not nullptr, and we can save the postfix here\r\n                if (!completeText && !processingToken.interTokenState)\r\n                {\r\n                    auto state = new InterTokenState;\r\n                    state->postfix = postfix;\r\n                    processingToken.interTokenState = state;\r\n                }\r\n            }\r\n        }\r\n    };\r\n\r\n    RegexLexer lexer(tokenDefs, proc);\r\n    RegexLexerColorizer colorizer = lexer.Colorize();\r\n\r\n    void* lastInterTokenState = nullptr;\r\n    FOREACH_INDEXER(const wchar_t*, line, index, From(lines))\r\n    {\r\n        Console::WriteLine(L\"Begin line \" + itow(index));\r\n        argument.processingText = line;\r\n        void* interTokenState = colorizer.Colorize(line, wcslen(line));\r\n        \r\n        if (lastInterTokenState && lastInterTokenState != interTokenState)\r\n        {\r\n            // call the deleter manually\r\n            proc.deleter(lastInterTokenState);\r\n        }\r\n        lastInterTokenState = interTokenState;\r\n\r\n        argument.processingText = nullptr;\r\n        colorizer.Pass(L'\\r');\r\n        colorizer.Pass(L'\\n');\r\n        Console::WriteLine(L\"\");\r\n    }\r\n}",
            "language": "C++"
          }
        ]
      }
    ]
  }
};
  window["MVC-Resources.mvcModel"] = mvcModel;
  window["MVC-Resources.mvcViews"] = mvcViews;
  window["MVC-Resources.activeButton"] = activeButton;
  window["MVC-Resources.activeCategory"] = activeCategory;
  window["MVC-Resources.homeArticle"] = homeArticle;
  window["MVC-Resources.categoryArticle"] = categoryArticle;
  for (const view of mvcViews) {
    window[view.viewName].renderView(mvcModel, document.getElementById(view.targetObject));
  }
  const renderedScriptTags = document.getElementById("MVC-ViewContainer").getElementsByTagName("script");
  for (const scriptTag of renderedScriptTags) {
    eval(
      "(function(){" + scriptTag.innerHTML + "})()"
    );
  }
}
</script>
</body>
</html>
